# **LCMR-3S: Learning Cross-modality Representation via Selective State Space Model for Depression Detection on Social Media**

[Quang Vinh Nguyen](https://github.com/vinhhust2806), 
Thanh Dong Nguyen,
Duy Duc Nguyen,
Doan Khai Ta,
Ji-Eun Shin,
Seung-Won Kim,
Hyung-Jeong Yang,
Soo-Hyung Kim

Official PyTorch implementation

<hr />


# :fire: News
* **(September xx, 2024)**
  * Paper submmited at ****** 2025!ðŸŽŠ
<hr />

### Data

The Reddit and Twitter multimodal data used in our experiments are from the work of:

Uban, Ana-Sabina, Berta Chulvi, and Paolo Rosso. [Explainability of Depression Detection on Social Media: From Deep Learning Models to Psychological Interpretations and Multimodality](https://link.springer.com/chapter/10.1007/978-3-031-04431-1_13). In Early Detection of Mental Health Disorders by Social Media Monitoring, pp. 289-320. Springer, Cham, 2022.

Gui, Tao, Liang Zhu, Qi Zhang, Minlong Peng, Xu Zhou, Keyu Ding, and Zhigang Chen. [Cooperative Multimodal Approach to Depression Detection in Twitter](https://ojs.aaai.org/index.php/AAAI/article/view/3775). In Proceedings of the AAAI conference on Artificial Intelligence, vol. 33, no. 01, pp. 110-117. 2019.

Please contact the respective authors for accessing the data.

### Running experiments

Our model definition can be found in the `models/` folder. 

Training and Evaluating Experiments are defined in the bash script in `experiments/run_experiments.sh`.
